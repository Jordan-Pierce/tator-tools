{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "from tator_tools.download_media import MediaDownloader\n",
    "from tator_tools.fiftyone_clustering import FiftyOneDatasetViewer\n",
    "from tator_tools.download_datasets import DatasetDownloader\n",
    "from tator_tools.yolo_dataset import YOLODataset\n",
    "from tator_tools.train_model import ModelTrainer\n",
    "from tator_tools.inference_video import VideoInferencer\n",
    "\n",
    "from yolo_tiler import YoloTiler, TileConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Media (video -> frames) from Tator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the downloader with the required parameters\n",
    "downloader = MediaDownloader(\n",
    "    api_token=os.getenv(\"TATOR_TOKEN\"),\n",
    "    project_id=155,\n",
    "    output_dir=\"../Data\"\n",
    ")\n",
    "\n",
    "# Download the media\n",
    "media_ids = [\"14759824\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.download_data(media_ids,             # Download these videos\n",
    "                         convert=False,         # Convert the videos to MP4\n",
    "                         extract=True,          # Extract frames from the videos\n",
    "                         every_n_seconds=3)     # Extract 1 frame every 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Clustered Frames from Tator using Fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the viewer with the path to the directory containing images\n",
    "viewer = FiftyOneDatasetViewer(image_dir=downloader.image_dir)\n",
    "\n",
    "# Process the dataset to create the FiftyOne dataset and generate the UMAP visualization\n",
    "viewer.process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the FiftyOne app\n",
    "try:\n",
    "    session = fo.launch_app(viewer.dataset)\n",
    "except:\n",
    "    # Weird behavior in notebook\n",
    "    session = fo.launch_app(viewer.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Datasets from Tator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "api_token = os.getenv(\"TATOR_TOKEN\")\n",
    "project_id = 70  # 155\n",
    "\n",
    "# Search string comes from Tator's Data Metadata Export utility\n",
    "search_string = \"eyJtZXRob2QiOiJBTkQiLCJvcGVyYXRpb25zIjpbeyJhdHRyaWJ1dGUiOiJTY2llbnRpZmljTmFtZSIsIm9wZXJhdGlvbiI6ImlzbnVsbCIsImludmVyc2UiOnRydWUsInZhbHVlIjp0cnVlfSx7ImF0dHJpYnV0ZSI6IkluZGl2aWR1YWxDb3VudCIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjoiMSJ9LHsiYXR0cmlidXRlIjoiJHZlcnNpb24iLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NDk5fSx7Im1ldGhvZCI6Ik9SIiwib3BlcmF0aW9ucyI6W3siYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NTU0fSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjE1Mn0seyJhdHRyaWJ1dGUiOiIkdHlwZSIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjo0NDh9LHsiYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NDYxfSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjUxMX0seyJhdHRyaWJ1dGUiOiIkdHlwZSIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjo1MTZ9LHsiYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NTU3fSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjE0N30seyJhdHRyaWJ1dGUiOiIkdHlwZSIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjozMTV9LHsiYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NDkzfSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjE0NH0seyJhdHRyaWJ1dGUiOiIkdHlwZSIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjo1MDB9LHsiYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6MjU2fSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjI1OH0seyJhdHRyaWJ1dGUiOiIkdHlwZSIsIm9wZXJhdGlvbiI6ImVxIiwiaW52ZXJzZSI6ZmFsc2UsInZhbHVlIjoxNzJ9LHsiYXR0cmlidXRlIjoiJHR5cGUiLCJvcGVyYXRpb24iOiJlcSIsImludmVyc2UiOmZhbHNlLCJ2YWx1ZSI6NDQwfSx7ImF0dHJpYnV0ZSI6IiR0eXBlIiwib3BlcmF0aW9uIjoiZXEiLCJpbnZlcnNlIjpmYWxzZSwidmFsdWUiOjI0N31dfV19\"\n",
    "\n",
    "# Demo for downloading labeled data\n",
    "frac = 1.0\n",
    "\n",
    "dataset_name = \"MR_Downward_Facing_Imagery\"\n",
    "output_dir = \"../Data/Labeled_Data\"\n",
    "\n",
    "label_field = \"ScientificName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a downloader for the labeled data\n",
    "downloader = DatasetDownloader(api_token,\n",
    "                               project_id=project_id,\n",
    "                               search_string=search_string,\n",
    "                               frac=frac,\n",
    "                               output_dir=output_dir,\n",
    "                               dataset_name=dataset_name,\n",
    "                               label_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the labeled data\n",
    "downloader.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.display_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downloader.as_dataframe()  # .as_dict()\n",
    "\n",
    "# Do some data exploration, filtering as needed\n",
    "# Example: Drop all rows where x, y, width, or height is NaN\n",
    "df = df.dropna(subset=[\"x\", \"y\", \"width\", \"height\"])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data into YOLO-formatted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "output_dir = \"../Data/Labeled_Data/MR_Downward_Facing_Imagery\"\n",
    "dataset_name = \"YOLODataset_Detection\"\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "\n",
    "task = 'detect' # 'detect' or 'segment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process dataset\n",
    "dataset = YOLODataset(\n",
    "    data=df,\n",
    "    output_dir=output_dir,\n",
    "    dataset_name=dataset_name,\n",
    "    train_ratio=train_ratio,\n",
    "    test_ratio=test_ratio,\n",
    "    task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the dataset\n",
    "dataset.process_dataset(move_images=False)  # Makes a copy of the images instead of moving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tile Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = dataset.dataset_dir               # Source YOLO dataset directory\n",
    "dst = f\"{dataset.dataset_dir}_Tiled\"    # Output directory for tiled dataset\n",
    "\n",
    "config = TileConfig(\n",
    "    # Size of each tile (width, height). Can be:\n",
    "    # - Single integer for square tiles: slice_wh=640\n",
    "    # - Tuple for rectangular tiles: slice_wh=(640, 480)\n",
    "    slice_wh=(1920, 1080),\n",
    "\n",
    "    # Overlap between adjacent tiles. Can be:\n",
    "    # - Single float (0-1) for uniform overlap percentage: overlap_wh=0.1\n",
    "    # - Tuple of floats for different overlap in each dimension: overlap_wh=(0.1, 0.1)\n",
    "    # - Single integer for pixel overlap: overlap_wh=64\n",
    "    # - Tuple of integers for different pixel overlaps: overlap_wh=(64, 48)\n",
    "    overlap_wh=(0.2, 0.2),\n",
    "\n",
    "    # Input image file extension to process\n",
    "    input_ext=\".jpg\",\n",
    "\n",
    "    # Output image file extension to save (default: same as input_ext)\n",
    "    output_ext=None,\n",
    "\n",
    "    # Type of YOLO annotations to process:\n",
    "    # - \"object_detection\": Standard YOLO format (class, x, y, width, height)\n",
    "    # - \"instance_segmentation\": YOLO segmentation format (class, x1, y1, x2, y2, ...)\n",
    "    annotation_type=\"object_detection\",\n",
    "\n",
    "    # Include negative samples (tiles without any instances)\n",
    "    include_negative_samples=True\n",
    ")\n",
    "\n",
    "tiler = YoloTiler(\n",
    "    source=src,\n",
    "    target=dst,\n",
    "    config=config,\n",
    "    num_viz_samples=15,                     # Number of samples to visualize\n",
    "    show_processing_status=True,            # Show the progress of the tiling process\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"E:\\\\tator-tools\\\\Data\\\\Labeled_Data\\\\MR_Downward_Facing_Imagery\\\\YOLODataset_Detection\"\n",
    "\n",
    "# Initialize the trainer with the required parameters\n",
    "trainer = ModelTrainer(\n",
    "    training_data=f\"{dir_}\\\\data.yaml\",\n",
    "    weights=\"yolov8m.pt\",\n",
    "    output_dir=f\"{dir_}\\\\Training\",\n",
    "    name=\"yolov8m\",\n",
    "    task='detect',\n",
    "    epochs=50,\n",
    "    half=True,\n",
    "    imgsz=640,\n",
    "    single_cls=False,\n",
    "    plots=True,\n",
    "    batch=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the model (if test data is available)\n",
    "trainer.evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_weights = \"E:\\\\tator-tools\\\\Data\\\\Labeled_Data\\\\AUV_Polygons\\\\YOLODataset_Detection_Tiled\\\\Training\\\\AUV_Polygons_Detection\\\\weights\\\\best.pt\"\n",
    "\n",
    "video_path = \"E:\\\\tator-tools\\\\Data\\\\Raw_Videos\\\\GL2301_VID_20230725T145731Z_D015_DROPCAM_HIGH_converted.mp4\"\n",
    "output_dir = \"E:\\\\tator-tools\\\\Data\\\\Inference_Results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = VideoInferencer(\n",
    "    weights_path=model_weights,\n",
    "    model_type='yolo',\n",
    "    video_path=video_path,\n",
    "    output_dir=output_dir,\n",
    "    start_at=1000,\n",
    "    end_at=2000,\n",
    "    conf=0.5,\n",
    "    iou=0.3,\n",
    "    track=False,\n",
    "    segment=False,\n",
    "    sahi=False,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer.inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
